---
title: "Patagonia parrots density analysis"
author: "Francisco Denes and Peter Solymos"
date: "June 8, 2018"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
  word_document:
  html_document:
    df_print: paged
header-includes: \usepackage{float}

editor_options: 
  chunk_output_type: console

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.pos = 'H')
```

# Motivation

We want to model the density of the austral parakeet *Enicognathus ferrugineus* and the slender-billed parakeet *Enicognathus leptorhynchus* from count data obtained with road transect surveys in Patagonia. Because these parrots are gregarious, we want to assess whether group size and size of groups vary across habitats (classified as 'urban', 'agropastoral' and 'other' (i.e. various natural forest formations), and between breeding (Nov-Dec) and non-breeding seasons (Jan-Oct).
We use distance sampling methods to account for detectability of parrots.

These animals tend to form smaller or larger groups, but groups of size 2 are also often observed as a result of mating pairs, as shown in Figure 1.

```{r, echo=FALSE, fig.cap="\\textit{Enicognathus ferrugineus} count frequencies",out.extra=''}
obs_fer <- read.csv("C:/Users/voeroesd/Dropbox/EBD/Loros Patagonia/pat_obs_fer.csv")

x <- as.data.frame(obs_fer)


plot(table(x$count), ylab="Individuals")

# new variable identifying pairs from other groups
x$pair<-0
x$pair[which(x$count==2)]<-1
```

# Austral parakeet *Enicognathus ferrugineus*

##Estimating effective detection radius (EDR)

We fit distance sampling models with detection predictor variables, including the average group size, the number of groups that were observed (to account for the possibility that grouping behaviour influences detectability), and also habitat type. We used forward-stepwise model selection, starting with single covariate models and eliminating  covariates that do not improve model parsimony (i.e. result in dAIC < 2) in relation to the null model.

```{r, echo=FALSE, warning=F,message=F}
## Estimating effective detection radius (EDR) ####

x$distance[x$distance == 500] <- 300 # correct outlier
library(mefa4)
library(detect)

# Define distance bins
br <- seq(0, 320, by=20)
x$bin <- cut(x$distance, br,  include.lowest = TRUE)

x$pres <- 1

x$groupid <- 0
for (i in unique(x$site)) {
    ii <- x$site == i
    x[ii, "groupid"] <- seq_len(sum(ii))
}
x$site_g <- paste0(x$site, "_", x$groupid)


# Matrix with binned detection distances in each site
Y <- as.matrix(Xtab(pres ~site + bin, x))

# Dataframe for covariate vectors
## sum of all inds in all groups
X <- data.frame(ntot=rowSums(Xtab(count ~site + bin, x)))
## number of pairs / site
tmp <- aggregate(x[,c("pair"),drop=FALSE], list(Site=x$site), sum)
stopifnot(all(rownames(X) == as.character(tmp$Site)))
X$pair <- tmp$pair
## number of groups / site
tmp <- aggregate(x[,c("groupid"),drop=FALSE], list(Site=x$site), max)
X$ngroups <- tmp$groupid
## average group size = ntot / ngroups
X$gavg <- X$ntot / X$ngroups
## the rest is just repeated, so we take the unique values
tmp <- nonDuplicated(x, site, TRUE)
X <- data.frame(X, tmp[rownames(X), c("jdate", "Urban", "Agropastoral","site")])



D <- matrix(br[-1], nrow(Y), length(br)-1, byrow=TRUE)
rownames(X) <- rownames(D) <- rownames(Y)
colnames(D) <- colnames(Y)
```


```{r, echo=FALSE, warning=F,message=F}
EDR.null <- cmulti(Y | D ~1, type="dis")
#summary(EDR.null)

EDR.avggroupsize <- cmulti(Y | D ~ gavg, X, type="dis")
#summary(EDR.avggroupsize)


EDR.numbergroups <- cmulti(Y | D ~ ngroups, X, type = "dis")
#summary(EDR.numbergroups)

EDR.habitatype <- cmulti(Y | D ~ Urban + Agropastoral, X, type = "dis")


library(knitr)

kable(cbind(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype)[order(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype)$AIC),],dAIC=round(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype)[order(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype)$AIC),2]-AIC(EDR.habitatype),2)),caption ="\\textit{E. ferrugineous} EDR models AIC")
```

The model (`EDR.habitatype`) has the lowest AIC (Table 1), indicating that habitat type affects the effective detection radius (EDR) of *Enicognathus ferrugineus*. Specifically, detection radius is higher in agropastoral than urban and other habitats (Table 2). This means that detectability is higher in agropastoral habitats, and also that the area surveyed in a given sample unit is larger if the habitat therein is agropastoral vs. urban or other, presumably because it is possible to see further in pastures and planted fields than in forest or urban environments.

```{r, echo=FALSE, warning=F,message=F}
kable(summary(EDR.habitatype)$coefficients,digits = 3,caption="\\textit{E. ferrugineous} top-ranked EDR model estimates")
```

```{r, echo=FALSE, warning=F,message=F}
kable(data.frame("Habitat"=c("Other","Urban","Agropastoral"), EDR= c( exp(coef(EDR.habitatype))[1],exp(sum(coef(EDR.habitatype)[1:2])),exp(sum(coef(EDR.habitatype)[c(1,3)])))),caption="\\textit{E. ferrugineous} habitat-specific EDR (m)")
```

## Models for number of groups

We then model the number of groups as a function of covariates. The model for number of groups is G~i~ ~ Poisson(D~i~A~i~), where D~i~ = covariates and A~i~ = area sampled in site _i_. A~i~ is calculated using the habitat-specific estimated EDR, and is added to the model as an offset.



```{r, echo=FALSE, warning=F,message=F, fig.cap="\\textit{Enicognathus ferrugineus} group numbers ",out.extra=''}
## Estimating area surveyed for each site (km^2^), using the EDR for the respective habitat. The area surveyed is used subsequently to estimate densities.
sites <- read.csv("C:/Users/voeroesd/Dropbox/EBD/Loros Patagonia/pat_site.csv")


sites$A <- sites$habitat.length.km*(2*exp(coef(EDR.habitatype))[1]/1000)
for (i in 1:nrow(sites)){
  if (sites$habitat[i]=="Urban"){
    sites$A[i] <- sites$habitat.length.km[i]*(2*exp(sum(coef(EDR.habitatype)[1:2]))/1000)
  }
  if (sites$habitat[i]=="Agropastoral"){
    sites$A[i] <- sites$habitat.length.km[i]*(2*exp(sum(coef(EDR.habitatype)[c(1,3)]))/1000)
  }
}

sites$ngroups<- 0
sites$ngroups[which(sites$site%in%X$site)]<-X$ngroups

sites <- sites[!is.na(sites$A) & sites$habitat.length.km>0,]

plot(table(sites$ngroups), ylab="Number of groups")

```

### Model selection

For number of groups, we use a stage-wise selection procedure. First, we build a first set of models to evaluate the effect of covariates related to habitat (habitat type and elevation).

```{r, echo=FALSE, warning=F,message=F}
ngroup.hab <- glm(ngroups~habitat, family=poisson, data=sites, offset=log(sites$A))

ngroup.ele <- glm(ngroups~elevation, family=poisson, data=sites, offset=log(sites$A))

ngroup.ele2 <- glm(ngroups~elevation+I(elevation^2), family=poisson, data=sites, offset=log(sites$A))

ngroup.hab.ele <- glm(ngroups~habitat+elevation, family=poisson, data=sites, offset=log(sites$A))

ngroup.hab.ele2 <- glm(ngroups~habitat+elevation+I(elevation^2), family=poisson, data=sites, offset=log(sites$A))

kable(cbind(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)[order(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)$AIC),],dAIC=round(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)[order(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)$AIC),2]-AIC(ngroup.hab.ele2),2)),caption ="\\textit{E. ferrugineous} number of group models")
```

The model with both habitat type and elevation (quadratic effect) has the lowest AIC (Table 4), indicating that both covariates affect the number of groups:

```{r, echo=FALSE, warning=F,message=F}
kable(summary(ngroup.hab.ele2)$coefficients,digits = 3,caption="\\textit{E. ferrugineous} 'ngroup.hab.ele2' model estimates")

kable(anova(ngroup.hab.ele2), digits=3,caption="Deviance partitioning of 'ngroup.hab.ele2' model for \\textit{E. ferrugineous}")



```

We then proceed by adding within-year temporal covariates (breeding/non-breeding season and Julian date) and their interactions with habitat.

```{r, echo=FALSE, warning=F,message=F}
ngroup.hab.season.ele2 <- glm(ngroups~habitat+elevation+I(elevation^2)+season, family=poisson, data=sites, offset=log(sites$A))

ngroup.hab.jdate.ele2 <- glm(ngroups~habitat+elevation+I(elevation^2)+jdate, family=poisson, data=sites, offset=log(sites$A))

ngroup.habXseason.ele2 <- glm(ngroups~elevation+I(elevation^2)+habitat*season, family=poisson, data=sites, offset=log(sites$A))

ngroup.habXjdate.ele2 <- glm(ngroups~elevation+I(elevation^2)+habitat*jdate, family=poisson, data=sites, offset=log(sites$A))


kable(cbind(AIC(ngroup.hab.ele2,ngroup.hab.season.ele2,ngroup.hab.jdate.ele2,ngroup.habXseason.ele2,ngroup.habXjdate.ele2)[order(AIC(ngroup.hab.ele2,ngroup.hab.season.ele2,ngroup.hab.jdate.ele2,ngroup.habXseason.ele2,ngroup.habXjdate.ele2)$AIC),],dAIC=round(AIC(ngroup.hab.ele2,ngroup.hab.season.ele2,ngroup.hab.jdate.ele2,ngroup.habXseason.ele2,ngroup.habXjdate.ele2)[order(AIC(ngroup.hab.ele2,ngroup.hab.season.ele2,ngroup.hab.jdate.ele2,ngroup.habXseason.ele2,ngroup.habXjdate.ele2)$AIC),2]-AIC(ngroup.habXseason.ele2),2)), caption="\\textit{E. ferrugineous} number of group models (within-year temporal predictors) AIC")

```

The model with the season*habitat interaction (Table 8) is equally parsimonious with the model with only the additive effects (Table 9). Given these are nested models, this indicates the interaction only marginally improves the model fit, so will continue with model with season and no interaction:

```{r, echo=FALSE, warning=F,message=F}

kable(summary(ngroup.habXseason.ele2)$coefficients,digits = 3,caption="\\textit{E. ferrugineous} 'ngroup.habXseason.ele2' interaction model estimates")
```


```{r, echo=FALSE, warning=F,message=F}

kable(summary(ngroup.hab.season.ele2)$coefficients,digits = 3,caption="\\textit{E. ferrugineous} 'ngroup.hab.season.ele2' additive model estimates")

```

Finally, we assess year effects by adding a year covariate (2013-2016).
```{r, echo=FALSE, warning=F,message=F}
ngroup.hab.season.ele2.year <- glm(ngroups~habitat+elevation+I(elevation^2)+season+as.factor(year), family=poisson, data=sites, offset=log(sites$A))

kable(cbind(AIC(ngroup.hab.season.ele2,ngroup.hab.season.ele2.year)[order(AIC(ngroup.hab.season.ele2,ngroup.hab.season.ele2.year)$AIC),],dAIC=round(AIC(ngroup.hab.season.ele2,ngroup.hab.season.ele2.year)[order(AIC(ngroup.hab.season.ele2,ngroup.hab.season.ele2.year)$AIC),2]-AIC(ngroup.hab.season.ele2.year),2)),caption ="\\textit{E. ferrugineous} number of group models (year predictor) AIC table")
```

The model with lowest AIC indicates that the number of groups is affected by habitat type, elevation, season (breeding/non breeding) and year.

```{r, echo=FALSE, warning=F,message=F}
kable(summary(ngroup.hab.season.ele2.year)$coefficients,digits = 3,caption="\\textit{E. ferrugineous} top-ranked (ngroup.hab.season.ele2.year) model estimates")
kable(anova(ngroup.hab.season.ele2.year), digits=3,caption="Deviance partitioning of top-ranked 'ngroup.hab.season.ele2.year' model for \\textit{E. ferrugineous}")

```

## Models for group size

The count distribution is characterized with a spike at 2 (Figure 1), and by the absence of 0s due to group size being conditional on having >0 birds to consider it a group.

We start developing a general V-Inflated Poisson (VIP) model ("V" stands for "variable", in reference to the "Z" representing 0 in a zero-inflated Poisson model, or ZIP), then we add the >0 condition.

R functions for the VIP model are presented at the end of this document, including simulations to check the estimating procedure.

### Maximum likelihood

Let $Y$ be a random variable, and $y$ are observations, $V$ is the count value
that has some extra probability mass ($V=0$ is the ZIP model), $f(y; \lambda)$
is the Poisson density ($f(y; \lambda) = e^{-\lambda} \frac{\lambda^{y}}{y!}$).

The V-Inflated density can be written as $P(Y=y) = \phi I(Y=V) + (1-\phi) f(y; \lambda)$
which is $\phi + (1-\phi) f(V; \lambda)$ when $Y=V$ and
$(1-\phi) f(y; \lambda)$ otherwise.



```{r, echo=F, warning=F, message=F}
library(DEoptim)
library(Matrix)

vip <-
function(Y, X, Z, V=0,
offsetx, offsetz, weights, linkz="logit",
truncate=FALSE, hessian=TRUE, method="Nelder-Mead", init=NULL, ...) {
    if (missing(Y))
        stop("C'mon, you must have some data?!")
    if (truncate && any(Y < 1))
        stop("Y must be >0 when truncate=TRUE")
    n <- length(Y)
    id0 <- Y == V
    id1 <- !id0
    if (missing(X)) {
        X <- matrix(1, n, 1)
        colnames(X) <- "(Intercept)"
    }
    if (missing(Z)) {
        Z <- matrix(1, n, 1)
        colnames(Z) <- "(Intercept)"
    }
    kx <- ncol(X)
    kz <- ncol(Z)
    if (missing(offsetx))
        offsetx <- 0
    if (missing(offsetz))
        offsetz <- 0
    if (missing(weights))
        weights <- rep(1, n)
    linkinvx <- poisson("log")$linkinv
    linkinvz <- binomial(linkz)$linkinv
    good.num.limit <- c(.Machine$double.xmin, .Machine$double.xmax)^(1/3)

    ## VIP model full likelihood
    nll_VIP_ML <- function(parms) {
        mu <- as.vector(linkinvx(X %*% parms[1:kx] + offsetx))
        phi <- as.vector(linkinvz(Z %*% parms[(kx + 1):(kx + kz)] + offsetz))
        loglik0 <- log(phi + (1 - phi) * dpois(V, lambda = mu, log = FALSE))
        loglik1 <- log(1 - phi) + dpois(Y, lambda = mu, log = TRUE)
        loglik <- sum(weights[id0] * loglik0[id0]) + sum(weights[id1] * loglik1[id1])
        if (!is.finite(loglik) || is.na(loglik))
            loglik <- -good.num.limit[2]
        -loglik
    }
    ## 0-truncated VIP model full likelihood
    nll_VIP_TR <- function(parms) {
        mu <- as.vector(linkinvx(X %*% parms[1:kx] + offsetx))
        phi <- as.vector(linkinvz(Z %*% parms[(kx + 1):(kx + kz)] + offsetz))
        loglik0 <- log(phi + (1 - phi) * dpois(V, lambda = mu, log = FALSE) / (1-exp(-mu)))
        loglik1 <- log((1 - phi) * dpois(Y, lambda = mu, log = FALSE) / (1-exp(-mu)))
        loglik <- sum(weights[id0] * loglik0[id0]) + sum(weights[id1] * loglik1[id1])
        if (!is.finite(loglik) || is.na(loglik))
            loglik <- -good.num.limit[2]
        -loglik
    }
    .solvenear <-
    function(x)
    {
        xinv <- try(solve(x), silent = TRUE)
        if (inherits(xinv, "try-error"))
            xinv <- as.matrix(solve(Matrix::nearPD(x)$mat))
        xinv
    }
    if (is.null(init))

        init <- rep(0, kx+kz)
    nll <- if (truncate) nll_VIP_TR else nll_VIP_ML

    if (method == "DE") {
        DElimit <- 10
        up <- rep(DElimit, length(init))
        lo <- -up
        opt <- DEoptim(fn=nll, lower=lo, upper=up,
            control=list(trace=FALSE, itermax=length(init)*200))
        par <- opt$optim$bestmem
        names(par) <- c(paste0("P_", colnames(X)), paste0("V_", colnames(Z)))
        ll <- -opt$optim$bestval
        if (hessian) {
            hess <- optimHess(opt$optim$bestmem, nll)
            vc <- .solvenear(hess)
        } else {
            matrix(NA, length(par), length(par))
        }
    } else {
        opt <- optim(init, nll,
            hessian=hessian, method=method, ...)
        par <- opt$par
        names(par) <- c(paste0("P_", colnames(X)), paste0("V_", colnames(Z)))
        vc <- if (hessian)
            .solvenear(opt$hessian) else matrix(NA, length(par), length(par))
        ll <- -opt$value
    }

    dimnames(vc) <- list(names(par), names(par))
    out <- list(call=match.call(),
        coefficients=par, loglik=ll, vcov=vc, nobs=n,
        truncate=truncate, Y=Y, X=X, Z=Z, V=V,
        offsetx=offsetx, offsetz=offsetz, weights=weights, 
        linkz=linkz, method=method, init=init)
    class(out) <- "vip"
    out
}
vcov.vip <- function(object, ...) object$vcov
logLik.vip <- function (object, ...)
    structure(object$loglik, df = object$nobs - length(object$coef),
        nobs = object$nobs, class = "logLik")
summary.vip <- function (object, ...) {
    k <- length(object$coefficients)
    coefs <- coef(object)
    se <- sqrt(diag(vcov(object)))
    tstat <- coefs/se
    pval <- 2 * pnorm(-abs(tstat))
    coefs <- cbind(coefs, se, tstat, pval)
    colnames(coefs) <- c("Estimate", "Std. Error", "z value", "Pr(>|z|)")
    coefs <- coefs[1:k, , drop = FALSE]
    rownames(coefs) <- names(coef(object))
    out <- list(call = object$call, coefficients=coefs, loglik = object$loglik,
        bic=BIC(object), truncate=object$truncate)
    class(out) <- "summary.vip"
    return(out)
}
print.summary.vip <- function (x, digits, ...)
{
    if (missing(digits))
        digits <- max(3, getOption("digits") - 3)
    cat("\nCall:", deparse(x$call,
        width.cutoff = floor(getOption("width") * 0.85)), "", sep = "\n")
    cat("V-Inflated", if (x$truncate) "(Zero-Truncated)" else "", "Poisson Model\n\n")
    cat(paste("Coefficients:\n", sep = ""))
    printCoefmat(x$coefficients, digits = digits, signif.legend = FALSE)
    if (!any(is.na(array(x$coefficients)))) {
        if (getOption("show.signif.stars") & any(x$coefficients[,4] < 0.1))
            cat("---\nSignif. codes: ", "0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1", "\n")
    }
    cat("\nLog-likelihood:", formatC(x$loglik, digits = digits),
        "\nBIC =", formatC(x$bic, digits = digits), "\n")
    cat("\n")
    invisible(x)
}
confint.vip <-
function (object, parm, level = 0.95, ...)
{
    cf <- coef(object)
    pnames <- names(cf)
    if (missing(parm)) {
        parm <- pnames
    } else {
        if (is.numeric(parm))
            parm <- pnames[parm]
    }
    a <- (1 - level)/2
    a <- c(a, 1 - a)
    pct <- paste(format(100 * a, trim = TRUE, scientific = FALSE, digits = 3), "%", sep="")
    ci <- array(NA, dim = c(length(parm), 2), dimnames = list(parm, pct))
    fac <- qnorm(a)
    ses <- sqrt(diag(vcov(object, model, type)))
    ci[] <- cf[parm] + ses[parm] %o% fac
    ci
}

goodness <- function(object, maxcount=NULL) {
    if (is.null(maxcount))
        maxcount <- max(object$Y)
    COUNTS <- if (object$truncate)
        1L:max(object$Y) else 0L:maxcount
    
    P_obs <- table(object$Y) / nobs(object)
    P_obs <- as.numeric(P_obs[match(COUNTS, names(P_obs))])
    P_obs[is.na(P_obs)] <- 0
    names(P_obs) <- COUNTS
    
    P_exp <- P_obs
    P_exp[] <- 0
    
    linkinvx <- poisson("log")$linkinv
    linkinvz <- binomial(object$linkz)$linkinv
    parms <- coef(object)
    kx <- ncol(object$X)
    kz <- ncol(object$Z)
    mu <- as.vector(linkinvx(object$X %*% parms[1:kx] + object$offsetx))
    phi <- as.vector(linkinvz(object$Z %*% parms[(kx + 1):(kx + kz)] + object$offsetz))
    #id0 <- object$Y == object$V
    Pmat <- matrix(0, nobs(object), length(COUNTS))
    colnames(Pmat) <- COUNTS
    
    PV <- if (object$truncate) {
        log(phi + (1 - phi) * dpois(object$V, 
            lambda = mu, log = FALSE) / (1-exp(-mu)))
    } else {
        log(phi + (1 - phi) * dpois(object$V, lambda = mu, log = FALSE))
    }
    for (i in COUNTS) {
        PC <- if (object$truncate) {
            log((1 - phi) * dpois(i, lambda = mu, log = FALSE) / (1-exp(-mu)))
        } else {
            log(1 - phi) + dpois(i, lambda = mu, log = TRUE)
        }
        Pmat[,as.character(i)] <- if (i == object$V)
            exp(PV) else exp(PC)
    }
    P_exp <- colMeans(Pmat)
    cbind(P_obs=P_obs, P_exp=P_exp)
}


```

We define the extra probability mass at $V=2$ to account for the group size peak in pairs. The model is also truncated at 0, because there are no groups with 0 individuals. We include habitat type as a covariate for the count (Poisson) component, and compare models with and without season (breeding/non-breeding) as a covariate for the V-inflation probability.

```{r, echo=FALSE, warning=F,message=F}
x$A <- NA
for(i in 1:nrow(x)){
  x$A[i] <- sites$A[which(sites$site==x$site[i])]
}



X <- model.matrix(~Urban+Agropastoral,x)
Z <- model.matrix(~season, x)



set.seed(333)
VIP.habitat.season <- vip(Y=x$count, X=X, offsetx=log(x$A), V=2, Z=Z, truncate=TRUE, hessian=TRUE, method="DE")
```

### Goodness-of-fit

Model goodness-of-fit can be evaluated visually, inspecting the proportions of fitted values against the count distribution. Deviation from the 1:1 line can be used as a goodness-of-fit metric, with the better model showing smaller deviation. 

```{r, echo=FALSE, warning=F,message=F,fig.cap="\\textit{Enicognathus ferrugineus} group size model goodness-of-fit (red: null model; blue: habitat.season model). Better model is closer to 1:1 line.",out.extra=''}
# Goodness of fit test
## fit null model
mod0 <- vip(Y=x$count, X=X[,1,drop=FALSE], Z=Z[,1,drop=FALSE], V=2, truncate=TRUE, method="DE")
## calculate GoF for null and other model
gof0 <- goodness(mod0)
gof <- goodness(VIP.habitat.season)
## better model is closer to the 1:1 line
plot(gof0, type="b", col=2)
points(gof, type="b", col=4)
abline(0, 1, lty=2)
## better model will give smaller absolute deviation
#sum(abs(apply(gof0, 1, diff)))
#sum(abs(apply(gof, 1, diff)))

nboot<-10
```


The deviation of null model is `r round(sum(abs(apply(gof0, 1, diff))),2)`, and of the VIP.habitat.season model is `r round(sum(abs(apply(gof, 1, diff))),2)`. 

### Confidence intervals for model estimates  
  
Estimated model coefficients (Table 13) indicate that group sizes are larger in urban ($\beta$ = `r round(coef(VIP.habitat.season)[2],3)`) and agropastoral ($\beta$ = `r round(coef(VIP.habitat.season)[2],3)`) habitats when compared to other natural habitats. Moreover, the probability of there being extra pairs (i.e. the V-inflation probability, $\phi$) is smaller in the non-breeding season ($\beta$ = `r round(coef(VIP.habitat.season)[2],3)`).   

```{r, echo=FALSE, warning=F,message=F}
kable(summary(VIP.habitat.season)$coefficients,digits = 3,caption="\\textit{E. ferrugineous} group size model estimates")
```

Confidence intervals (CI) based on estimated standard errors can be obtained (Table 14):  

```{r, echo=FALSE, warning=F,message=F}
kable(confint(VIP.habitat.season),digits = 3,caption="\\textit{E. ferrugineous} group size model CI")
```

Alternatively, we can estimate confidence intervals based on quantiles using bootstrap samples (with n=`r nboot`) for the estimated coefficients (Table 15).  

```{r, echo=FALSE, warning=F,message=F}
## Bootstrapping for the model:

dflist<-as.list(rep(NA,nboot))

bootsample<-function(df){# stratifying sampling by season
  non.breeding<-x[which(x$season=="non-breeding"),]
  row.names(non.breeding)<-1:nrow(non.breeding)
  set.seed(123)
  sample.non.breeding<-non.breeding[sample(nrow(non.breeding),size=nrow(non.breeding),replace = TRUE),]

  breeding<-x[which(x$season=="breeding"),]
  row.names(breeding)<-1:nrow(breeding)
  set.seed(123)
  sample.breeding<-breeding[sample(nrow(breeding),size=nrow(breeding),replace = TRUE),]

  rbind(sample.non.breeding,sample.breeding)
}

dflist<-lapply(dflist,bootsample)

# fit model to all bootstrap samples:
VIP.model.fun<-function(df){
  X <- model.matrix(~Urban+Agropastoral,df)
  Z <- model.matrix(~season, df)

  inits<-c(coef(glm(x$count~x$Urban+x$Agropastoral,family=poisson)),0,0)

  
  VIP.habitat.season <- vip(Y=df$count, X=X, offsetx=log(df$A), V=2, Z=Z, truncate=TRUE, hessian=T, method="DE", init=inits)
}

VIPs<-lapply(dflist,VIP.model.fun)


# get means from coefs, and CI based on quantiles
VIP.boot.coefs<-mapply(FUN=function(x){coef(x)},VIPs)

VIP.boot.coefs<-rbind(coef(VIP.habitat.season), t(sapply(VIPs, coef)))
coefCIs<-t(rbind(VIP.boot.coefs[1,], apply(VIP.boot.coefs, 2, quantile, c(0.025,0.975))))
colnames(coefCIs)<-c("Estimate","2.5%","97.5%")


kable(round(coefCIs,3),caption =paste0("Estimated coefficients and 95% CI based on bootstrap sample (n= ",nboot ,") quantiles for \\textit{E. ferrugineous} group size models"))

```


***
# Slender-billed parakeet *Enicognathus leptorhynchus*
```{r, echo=FALSE, fig.cap="\\textit{Enicognathus leptorhynchus} count frequencies",out.extra=''}
obs_lep <- read.csv("C:/Users/voeroesd/Dropbox/EBD/Loros Patagonia/pat_obs_lep.csv")
x <- as.data.frame(obs_lep)

plot(table(x$count), ylab="Individuals")

# new variable identifying pairs from other groups
x$pair<-0
x$pair[which(x$count==2)]<-1
```

##Estimating effective detection radius (EDR)

We follow the same procedure used for the austral parakeet above.

```{r, echo=FALSE, warning=F,message=F}
## Estimating effective detection radius (EDR) ####

x$distance[x$distance == 2000] <- 1000 # correct outlier


# Define distance bins
br <- seq(0, 1100, by=100)
x$bin <- cut(x$distance, br,  include.lowest = TRUE)

x$pres <- 1

x$groupid <- 0
for (i in unique(x$site)) {
    ii <- x$site == i
    x[ii, "groupid"] <- seq_len(sum(ii))
}
x$site_g <- paste0(x$site, "_", x$groupid)


# Matrix with binned detection distances in each site
Y <- as.matrix(Xtab(pres ~site + bin, x))

# Dataframe for covariate vectors
## sum of all inds in all groups
X <- data.frame(ntot=rowSums(Xtab(count ~site + bin, x)))
## number of pairs / site
tmp <- aggregate(x[,c("pair"),drop=FALSE], list(Site=x$site), sum)
stopifnot(all(rownames(X) == as.character(tmp$Site)))
X$pair <- tmp$pair
## number of groups / site
tmp <- aggregate(x[,c("groupid"),drop=FALSE], list(Site=x$site), max)
X$ngroups <- tmp$groupid
## average group size = ntot / ngroups
X$gavg <- X$ntot / X$ngroups
## the rest is just repeated, so we take the unique values
tmp <- nonDuplicated(x, site, TRUE)
X <- data.frame(X, tmp[rownames(X), c("jdate", "Urban", "Agropastoral","site")])



D <- matrix(br[-1], nrow(Y), length(br)-1, byrow=TRUE)
rownames(X) <- rownames(D) <- rownames(Y)
colnames(D) <- colnames(Y)
```


```{r, echo=FALSE, warning=F,message=F}
EDR.null <- cmulti(Y | D ~1, type="dis")
#summary(EDR.null)

EDR.avggroupsize <- cmulti(Y | D ~ gavg, X, type="dis")
#summary(EDR.avggroupsize)

EDR.numbergroups <- cmulti(Y | D ~ ngroups, X, type = "dis")
#summary(EDR.numbergroups)

EDR.habitatype <- cmulti(Y | D ~ Urban + Agropastoral, X, type = "dis")
#summary(EDR.habitatype)

EDR.avggroupsize.habitat <- cmulti(Y | D ~ gavg + Urban + Agropastoral, X, type="dis")
#summary(EDR.avggroupsize.habitat)

EDR.avggroupsize.numbergroups <- cmulti(Y | D ~ gavg + ngroups, X, type="dis")
#summary(EDR.avggroupsize.numbergroups)

EDR.habitat.numbergroups <- cmulti(Y | D ~ Urban + Agropastoral + ngroups, X, type="dis")
#summary(EDR.habitat.numbergroups)

EDR.habitat.avggroupsize.numbergroups <- cmulti(Y | D ~ Urban + Agropastoral +gavg + ngroups, X, type="dis")
#summary(EDR.habitat.avggroupsize.numbergroups)


kable(cbind(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype,EDR.avggroupsize.habitat,EDR.avggroupsize.numbergroups,EDR.habitat.numbergroups,EDR.habitat.avggroupsize.numbergroups)[order(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype,EDR.avggroupsize.habitat,EDR.avggroupsize.numbergroups,EDR.habitat.numbergroups,EDR.habitat.avggroupsize.numbergroups)$AIC),],dAIC=round(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype,EDR.avggroupsize.habitat,EDR.avggroupsize.numbergroups,EDR.habitat.numbergroups,EDR.habitat.avggroupsize.numbergroups)[order(AIC(EDR.null,EDR.avggroupsize,EDR.numbergroups,EDR.habitatype,EDR.avggroupsize.habitat,EDR.avggroupsize.numbergroups,EDR.habitat.numbergroups,EDR.habitat.avggroupsize.numbergroups)$AIC),2]-AIC(EDR.avggroupsize.habitat),2)),caption ="\\textit{E. leptorhynchus} EDR models AIC")
```

The model (`EDR.avggroupsize.habitat`) has the lowest AIC (Table 16), indicating that habitat type and average group size affect the effective detection radius (EDR) of *Enicognathus leptorhynchus*. The mean EDR for each habitat, predicted using model coefficients and the habitat-specific means of average group size, is shown in Table 17.
```{r, echo=FALSE, warning=F,message=F}
kable(summary(EDR.avggroupsize.habitat)$coefficients,digits = 3,caption="\\textit{E. leptorhynchus} top-ranked EDR model estimates")

gsizemeansbyhab<-aggregate(X$gavg,by=list(X$Urban,X$Agropastoral),mean)


otherEDR<-exp(sum(coef(EDR.avggroupsize.habitat)[1],coef(EDR.avggroupsize.habitat)[2]*gsizemeansbyhab[1,3]))
urbanEDR<-exp(sum(coef(EDR.avggroupsize.habitat)[1:2],coef(EDR.avggroupsize.habitat)[2]*gsizemeansbyhab[2,3]))
agropastoralEDR<-exp(sum(coef(EDR.avggroupsize.habitat)[c(1,3)],coef(EDR.avggroupsize.habitat)[2]*gsizemeansbyhab[3,3]))

kable(data.frame("Habitat"=c("Other","Urban","Agropastoral"), EDR= c(otherEDR,urbanEDR,agropastoralEDR)) ,caption="\\textit{E. leptorhynchus} habitat-specific mean EDR (m)")

```


## Models for number of groups

As for the austral parakeet, the model for number of groups is G~i~ ~ Poisson(D~i~A~i~), where D~i~ = covariates and A~i~ = area sampled in site _i_. A~i~ is calculated using the habitat-specific estimated EDR, and is added to the model as an offset.

```{r, echo=FALSE, warning=F,message=F, fig.cap="\\textit{Enicognathus leptorhynchus} group numbers ",out.extra=''}
## Estimating area surveyed for each site (km^2^), using the EDR for the respective habitat. The area surveyed is used subsequently to estimate densities.
sites <- read.csv("C:/Users/voeroesd/Dropbox/EBD/Loros Patagonia/pat_site.csv")

sites$gavg<-0
sites$gavg[which(sites$site%in%X$site)]<-X$gavg

sites$A <- NA
for (i in 1:nrow(sites)){
  if (sites$habitat[i]=="Other"){
    sites$A[i] <- sites$habitat.length.km[i]*(2*exp(sum(coef(EDR.avggroupsize.habitat)[1],coef(EDR.avggroupsize.habitat)[2]*sites$gavg[i]))/1000)
  }
  if (sites$habitat[i]=="Urban"){
    sites$A[i] <- sites$habitat.length.km[i]*(2*exp(sum(coef(EDR.avggroupsize.habitat)[c(1,3)],coef(EDR.avggroupsize.habitat)[2]*sites$gavg[i]))/1000)
  }
  if (sites$habitat[i]=="Agropastoral"){
    sites$A[i] <- sites$habitat.length.km[i]*(2*exp(sum(coef(EDR.avggroupsize.habitat)[c(1,4)],coef(EDR.avggroupsize.habitat)[2]*sites$gavg[i]))/1000)
  }
}

sites$ngroups<- 0
sites$ngroups[which(sites$site%in%X$site)]<-X$ngroups



sites <- sites[!is.na(sites$A) & sites$habitat.length.km>0,]

plot(table(sites$ngroups), ylab="Number of groups")

```

### Model selection

First set of models to evaluate the effect of habitat type and elevation covariates (Table 18):

```{r, echo=FALSE, warning=F,message=F}
ngroup.hab <- glm(ngroups~habitat, family=poisson, data=sites, offset=log(sites$A))


ngroup.ele <- glm(ngroups~elevation, family=poisson, data=sites, offset=log(sites$A))

ngroup.ele2 <- glm(ngroups~elevation+I(elevation^2), family=poisson, data=sites, offset=log(sites$A))

ngroup.hab.ele <- glm(ngroups~habitat+elevation, family=poisson, data=sites, offset=log(sites$A))

ngroup.hab.ele2 <- glm(ngroups~habitat+elevation+I(elevation^2), family=poisson, data=sites, offset=log(sites$A))

kable(cbind(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)[order(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)$AIC),],dAIC=round(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)[order(AIC(ngroup.hab,ngroup.ele,ngroup.hab.ele,ngroup.ele2,ngroup.hab.ele2)$AIC),2]-AIC(ngroup.hab.ele2),2)),caption ="\\textit{E. leptorhynchus} number of group models")
```

The models 'ngroup.hab.ele' (with linear elevation effect) and 'ngroup.hab.ele2' (with quadratic effect) are equally parsimonious (Table 18), but the quadratic term in the latter is mostly uninformative (Tables 19-20). Given these are nested models, we drop the quadratic term and continue with the model with habitat and linear elevation effects.

```{r, echo=FALSE, warning=F,message=F}
kable(summary(ngroup.hab.ele)$coefficients,digits = 3,caption="\\textit{E. leptorhynchus} 'ngroup.hab.ele' model estimates")

kable(anova(ngroup.hab.ele), digits=3,caption="Deviance partitioning of 'ngroup.hab.ele' model for \\textit{E. leptorhynchus}")

```


Adding within-year temporal covariates (breeding/non-breeding season and Julian date) and their interactions with habitat:

```{r, echo=FALSE, warning=F,message=F}
ngroup.hab.ele.season <- glm(ngroups~habitat+elevation+season, family=poisson, data=sites, offset=log(sites$A))

ngroup.hab.ele.jdate <- glm(ngroups~habitat+elevation+jdate, family=poisson, data=sites, offset=log(sites$A))

ngroup.habXseason.ele <- glm(ngroups~elevation+habitat*season, family=poisson, data=sites, offset=log(sites$A))

ngroup.habXjdate.ele <- glm(ngroups~elevation+habitat*jdate, family=poisson, data=sites, offset=log(sites$A))


kable(cbind(AIC(ngroup.hab.ele,ngroup.hab.ele.season,ngroup.hab.ele.jdate,ngroup.habXseason.ele,ngroup.habXjdate.ele)[order(AIC(ngroup.hab.ele,ngroup.hab.ele.season,ngroup.hab.ele.jdate,ngroup.habXseason.ele,ngroup.habXjdate.ele)$AIC),],dAIC=round(AIC(ngroup.hab.ele,ngroup.hab.ele.season,ngroup.hab.ele.jdate,ngroup.habXseason.ele,ngroup.habXjdate.ele)[order(AIC(ngroup.hab.ele,ngroup.hab.ele.season,ngroup.hab.ele.jdate,ngroup.habXseason.ele,ngroup.habXjdate.ele)$AIC),2]-AIC(ngroup.habXjdate.ele),2)), caption="\\textit{E. leptorhynchus} number of group models (within-year temporal predictors) AIC")
```

The model 'ngroup.habXjdate.ele' has the lowest AIC (Table 21).


```{r, echo=FALSE, warning=F,message=F}

kable(summary(ngroup.habXjdate.ele)$coefficients,digits = 3,caption="\\textit{E. leptorhynchus} 'ngroup.habXjdate.ele' model estimates")

```

Finally, we assess year effects by adding a year covariate (2013-2016).
```{r, echo=FALSE, warning=F,message=F}
ngroup.habXjdate.ele.year <- glm(ngroups~habitat+elevation+season+as.factor(year), family=poisson, data=sites, offset=log(sites$A))

kable(cbind(AIC(ngroup.habXjdate.ele,ngroup.habXjdate.ele.year)[order(AIC(ngroup.habXjdate.ele,ngroup.habXjdate.ele.year)$AIC),],dAIC=round(AIC(ngroup.habXjdate.ele,ngroup.habXjdate.ele.year)[order(AIC(ngroup.habXjdate.ele,ngroup.habXjdate.ele.year)$AIC),2]-AIC(ngroup.habXjdate.ele.year),2)),caption ="\\textit{E. leptorhynchus} number of group models (year predictor) AIC table")
```

The best-ranked model indicates that the number of groups is affected by habitat type, elevation, Julian date and year (Tables 23-24).

```{r, echo=FALSE, warning=F,message=F}


kable(summary(ngroup.habXjdate.ele.year)$coefficients,digits = 3,caption="\\textit{E. leptorhynchus} 'ngroup.habXjdate.ele.year' model estimates")

kable(anova(ngroup.habXjdate.ele.year), digits=3,caption="Deviance partitioning of 'ngroup.habXjdate.ele.year' model for \\textit{E. leptorhynchus}")

```


## Models for group size

```{r, echo=FALSE, warning=F,message=F}
x$A <- NA
for(i in 1:nrow(x)){
  x$A[i] <- sites$A[which(sites$site==x$site[i])]
}

x<-x[which(x$count<1200),]
row.names(x)<-1:nrow(x)

X <- model.matrix(~Urban+Agropastoral,x)
Z <- model.matrix(~season, x)

set.seed(333)
#VIP.habitat.season <- vip(Y=x$count, X=X, offsetx=log(x$A), V=2, Z=Z, truncate=TRUE, hessian=F, method="DE", init=c(coef(glm(x$count~x$Urban+x$Agropastoral,family=poisson)),0,0))

VIP.habitat.season <- vip(Y=x$count, X=X, offsetx=log(x$A), V=2, Z=Z, truncate=TRUE, hessian=FALSE, method="SANN", init=c(coef(glm(x$count~x$Urban+x$Agropastoral,family=poisson)),0,0))
```

### Goodness-of-fit

Model goodness-of-fit can be evaluated visually, inspecting the proportions of fitted values against the count distribution. Deviation from the 1:1 line can be used as a goodness-of-fit metric, with the better model showing smaller deviation. 

```{r, echo=FALSE, warning=F,message=F,fig.cap="\\textit{Enicognathus leptorhynchus} group size model goodness-of-fit (red: null model; blue: habitat.season model). Better model is closer to 1:1 line.",out.extra=''}
# Goodness of fit test
## fit null model
mod0 <- vip(Y=x$count, X=X[,1,drop=FALSE], Z=Z[,1,drop=FALSE], V=2, truncate=TRUE, method="DE")
## calculate GoF for null and other model
gof0 <- goodness(mod0)
gof <- goodness(VIP.habitat.season)
## better model is closer to the 1:1 line
plot(gof0, type="b", col=2)
points(gof, type="b", col=4)
abline(0, 1, lty=2)
## better model will give smaller absolute deviation
#sum(abs(apply(gof0, 1, diff)))
#sum(abs(apply(gof, 1, diff)))

nboot<-10
```

The deviation of null model is `r round(sum(abs(apply(gof0, 1, diff))),2)`, and of the VIP.habitat.season model is `r round(sum(abs(apply(gof, 1, diff))),2)`. 

### Confidence intervals for model estimates  
```{r, echo=FALSE, warning=F,message=F}
kable(summary(VIP.habitat.season)$coefficients,digits = 3,caption="\\textit{E. leptorhynchus} group size model estimates")
```

Model-fitting function cannot estimate coefficient standard errors due to singular Hessian matrix (Table 25). We can calculate confidence intervals based on quantiles using bootstrap (with n=`r nboot`):

```{r, echo=FALSE, warning=F,message=F}
## Bootstrapping for the model:

dflist<-as.list(rep(NA,nboot))

bootsample<-function(df){# stratifying sampling by season
  non.breeding<-x[which(x$season=="non-breeding"),]
  row.names(non.breeding)<-1:nrow(non.breeding)
  set.seed(123)
  sample.non.breeding<-non.breeding[sample(nrow(non.breeding),size=nrow(non.breeding),replace = TRUE),]

  breeding<-x[which(x$season=="breeding"),]
  row.names(breeding)<-1:nrow(breeding)
  set.seed(123)
  sample.breeding<-breeding[sample(nrow(breeding),size=nrow(breeding),replace = TRUE),]

  rbind(sample.non.breeding,sample.breeding)
}

dflist<-lapply(dflist,bootsample)

# fit model to all bootstrap samples:
VIP.model.fun<-function(df){
  X <- model.matrix(~Urban+Agropastoral,df)
  Z <- model.matrix(~season, df)

  inits<-c(coef(glm(x$count~x$Urban+x$Agropastoral,family=poisson)),0,0)

  VIP.habitat.season <- vip(Y=df$count, X=X, offsetx=log(df$A), V=2, Z=Z, truncate=TRUE, hessian=F, method="SANN", init=inits)
}

VIPs<-lapply(dflist,VIP.model.fun)


# get means from coefs, and CI based on quantiles
VIP.boot.coefs<-mapply(FUN=function(x){coef(x)},VIPs)

VIP.boot.coefs<-rbind(coef(VIP.habitat.season), t(sapply(VIPs, coef)))
coefCIs<-t(rbind(VIP.boot.coefs[1,], apply(VIP.boot.coefs, 2, quantile, c(0.025,0.975))))
colnames(coefCIs)<-c("Estimate","2.5%","97.5%")


kable(round(coefCIs,3),caption ="Estimated coefficients and 95% CI based on bootstrap quantiles for \\textit{E. leptorhynchus} group size models")

```

***
# VIP model - R functions and simulations
###Peter SC3lymos

## Functions

The `vip` function does the optimization. `method` argument can take values
listed for `optim` and also `"DE"` for differential evolution algorithm.
If there are convergence issues with `"Nelder-Mead"`, try `"SANN"` and `"DE"`.

```{r}
library(DEoptim)
library(Matrix)
vip <-
function(Y, X, Z, V=0,
offsetx, offsetz, weights, linkz="logit",
truncate=FALSE, hessian=TRUE, method="Nelder-Mead", init=NULL, ...) {
    if (missing(Y))
        stop("C'mon, you must have some data?!")
    if (truncate && any(Y < 1))
        stop("Y must be >0 when truncate=TRUE")
    n <- length(Y)
    id0 <- Y == V
    id1 <- !id0
    if (missing(X)) {
        X <- matrix(1, n, 1)
        colnames(X) <- "(Intercept)"
    }
    if (missing(Z)) {
        Z <- matrix(1, n, 1)
        colnames(Z) <- "(Intercept)"
    }
    kx <- ncol(X)
    kz <- ncol(Z)
    if (missing(offsetx))
        offsetx <- 0
    if (missing(offsetz))
        offsetz <- 0
    if (missing(weights))
        weights <- rep(1, n)
    linkinvx <- poisson("log")$linkinv
    linkinvz <- binomial(linkz)$linkinv
    good.num.limit <- c(.Machine$double.xmin, .Machine$double.xmax)^(1/3)

    ## VIP model full likelihood
    nll_VIP_ML <- function(parms) {
        mu <- as.vector(linkinvx(X %*% parms[1:kx] + offsetx))
        phi <- as.vector(linkinvz(Z %*% parms[(kx + 1):(kx + kz)] + offsetz))
        loglik0 <- log(phi + (1 - phi) * dpois(V, lambda = mu, log = FALSE))
        loglik1 <- log(1 - phi) + dpois(Y, lambda = mu, log = TRUE)
        loglik <- sum(weights[id0] * loglik0[id0]) + sum(weights[id1] * loglik1[id1])
        if (!is.finite(loglik) || is.na(loglik))
            loglik <- -good.num.limit[2]
        -loglik
    }
    ## 0-truncated VIP model full likelihood
    nll_VIP_TR <- function(parms) {
        mu <- as.vector(linkinvx(X %*% parms[1:kx] + offsetx))
        phi <- as.vector(linkinvz(Z %*% parms[(kx + 1):(kx + kz)] + offsetz))
        loglik0 <- log(phi + (1 - phi) * dpois(V, lambda = mu, log = FALSE) / (1-exp(-mu)))
        loglik1 <- log((1 - phi) * dpois(Y, lambda = mu, log = FALSE) / (1-exp(-mu)))
        loglik <- sum(weights[id0] * loglik0[id0]) + sum(weights[id1] * loglik1[id1])
        if (!is.finite(loglik) || is.na(loglik))
            loglik <- -good.num.limit[2]
        -loglik
    }
    .solvenear <-
    function(x)
    {
        xinv <- try(solve(x), silent = TRUE)
        if (inherits(xinv, "try-error"))
            xinv <- as.matrix(solve(Matrix::nearPD(x)$mat))
        xinv
    }
    if (is.null(init))

        init <- rep(0, kx+kz)
    nll <- if (truncate) nll_VIP_TR else nll_VIP_ML

    if (method == "DE") {
        DElimit <- 10
        up <- rep(DElimit, length(init))
        lo <- -up
        opt <- DEoptim(fn=nll, lower=lo, upper=up,
            control=list(trace=FALSE, itermax=length(init)*200))
        par <- opt$optim$bestmem
        names(par) <- c(paste0("P_", colnames(X)), paste0("V_", colnames(Z)))
        ll <- -opt$optim$bestval
        if (hessian) {
            hess <- optimHess(opt$optim$bestmem, nll)
            vc <- .solvenear(hess)
        } else {
            matrix(NA, length(par), length(par))
        }
    } else {
        opt <- optim(init, nll,
            hessian=hessian, method=method, ...)
        par <- opt$par
        names(par) <- c(paste0("P_", colnames(X)), paste0("V_", colnames(Z)))
        vc <- if (hessian)
            .solvenear(opt$hessian) else matrix(NA, length(par), length(par))
        ll <- -opt$value
    }
    dimnames(vc) <- list(names(par), names(par))
    out <- list(call=match.call(),
        coefficients=par, loglik=ll, vcov=vc, nobs=n,
        truncate=truncate, Y=Y, X=X, Z=Z, V=V,
        offsetx=offsetx, offsetz=offsetz, weights=weights, 
        linkz=linkz, method=method, init=init)
    class(out) <- "vip"
    out
}
vcov.vip <- function(object, ...) object$vcov
logLik.vip <- function (object, ...)
    structure(object$loglik, df = object$nobs - length(object$coef),
        nobs = object$nobs, class = "logLik")
summary.vip <- function (object, ...) {
    k <- length(object$coefficients)
    coefs <- coef(object)
    se <- sqrt(diag(vcov(object)))
    tstat <- coefs/se
    pval <- 2 * pnorm(-abs(tstat))
    coefs <- cbind(coefs, se, tstat, pval)
    colnames(coefs) <- c("Estimate", "Std. Error", "z value", "Pr(>|z|)")
    coefs <- coefs[1:k, , drop = FALSE]
    rownames(coefs) <- names(coef(object))
    out <- list(call = object$call, coefficients=coefs, loglik = object$loglik,
        bic=BIC(object), truncate=object$truncate)
    class(out) <- "summary.vip"
    return(out)
}
print.summary.vip <- function (x, digits, ...)
{
    if (missing(digits))
        digits <- max(3, getOption("digits") - 3)
    cat("\nCall:", deparse(x$call,
        width.cutoff = floor(getOption("width") * 0.85)), "", sep = "\n")
    cat("V-Inflated", if (x$truncate) "(Zero-Truncated)" else "", "Poisson Model\n\n")
    cat(paste("Coefficients:\n", sep = ""))
    printCoefmat(x$coefficients, digits = digits, signif.legend = FALSE)
    if (!any(is.na(array(x$coefficients)))) {
        if (getOption("show.signif.stars") & any(x$coefficients[,4] < 0.1))
            cat("---\nSignif. codes: ", "0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1", "\n")
    }
    cat("\nLog-likelihood:", formatC(x$loglik, digits = digits),
        "\nBIC =", formatC(x$bic, digits = digits), "\n")
    cat("\n")
    invisible(x)
}
confint.vip <-
function (object, parm, level = 0.95, ...)
{
    cf <- coef(object)
    pnames <- names(cf)
    if (missing(parm)) {
        parm <- pnames
    } else {
        if (is.numeric(parm))
            parm <- pnames[parm]
    }
    a <- (1 - level)/2
    a <- c(a, 1 - a)
    pct <- paste(format(100 * a, trim = TRUE, scientific = FALSE, digits = 3), "%", sep="")
    ci <- array(NA, dim = c(length(parm), 2), dimnames = list(parm, pct))
    fac <- qnorm(a)
    ses <- sqrt(diag(vcov(object, model, type)))
    ci[] <- cf[parm] + ses[parm] %o% fac
    ci
}
```

## Simple case

```{r}
set.seed(123)
n <- 1000
lam <- 2 # poisson mean, can be a vector of length n
phi <- 0.4 # V-inflation probability, can be a vector of length n
V <- 2 # V is the count value, can be 0, 2, etc
y <- y0 <- rpois(n, lam)
a <- rbinom(n, 1, phi)
y[a > 0] <- V
table(Poisson=y0, Vinflated=y)

mod <- vip(Y=y, V=2)
summary(mod)
cbind(True=c(log_lam=log(lam), logit_phi=qlogis(phi)),
      Est=coef(mod))
```

## Covariates for the non-V part

```{r}
set.seed(123)
n <- 1000
x <- rnorm(n)
df <- data.frame(x=x)
X <- model.matrix(~x, df)
beta <- c(-0.5,-0.5) # Intercept and beta values for covariate
lam <- exp(X %*% beta) # poisson mean, can be a vector of length n
phi <- 0.4 # V-inflation probability, can be a vector of length n
V <- 2 # V is the count value, can be 0, 2, etc
y <- y0 <- rpois(n, lam)
a <- rbinom(n, 1, phi)
y[a > 0] <- V
table(Poisson=y0, Vinflated=y)
mod <- vip(Y=y, X=X, V=2)
summary(mod)
cbind(True=c(beta=beta, logit_phi=qlogis(phi)),
      Est=coef(mod))
```

## Methods

```{r}
coef(mod)
vcov(mod)
summary(mod)
confint(mod)
nobs(mod)
logLik(mod)
AIC(mod)
BIC(mod)
```


# Zero-truncated VIP

We can truncate counts to be larger than 0. We also need $V>0$
(for $V=0$ case, look into ZIP or conditional Poisson model).
Conceptually, the V-Inflation follows the
0-truncation (because we cannot observe 0, real truncated distribution).

The 0-truncated PDF is $P(Y=y \mid Y>0) = \frac{P(Y=y)}{1 - P(Y=0)}$.
The 0-truncated V-Inflated density is
$P(Y=y  \mid Y>0,V>0) = \phi I(Y=V) + (1-\phi) \frac{f(y; \lambda)}{1-f(0; \lambda)}$.
This can be achieved in the `vip` call by the argument `truncate=TRUE`.

Here we use covariates for both the V and non-V part.

```{r}
set.seed(1)
n <- 1000
x <- rnorm(n)
z <- runif(n, -1, 1)
df <- data.frame(x=x, z=z)
X <- model.matrix(~x, df)
Z <- model.matrix(~z, df)
beta <- c(-0.5, -0.5)
alpha <- c(0, 0.5)
lam <- exp(X %*% beta)
phi <- plogis(Z %*% alpha)
V <- 2 # V is the count value, cannot be 0
y <- y0 <- rpois(n, lam)
a <- rbinom(n, 1, phi)
keep <- y0>0
y <- y[keep] # conditioning (i.e. exclude 0s)
y0 <- y0[keep]
X <- X[keep,]
Z <- Z[keep,]
y[a[keep] > 0] <- V
table(Poisson=y0, Vinflated=y)

mod <- vip(Y=y, X=X, Z=Z, V=2, truncate=TRUE)
summary(mod)
cbind(True=c(beta=beta, alpha=alpha),
      Est=coef(mod))
```

# Goodness of fit

```{r}
goodness <- function(object, maxcount=NULL) {
    if (is.null(maxcount))
        maxcount <- max(object$Y)
    COUNTS <- if (object$truncate)
        1L:max(object$Y) else 0L:maxcount
    
    P_obs <- table(object$Y) / nobs(object)
    P_obs <- as.numeric(P_obs[match(COUNTS, names(P_obs))])
    P_obs[is.na(P_obs)] <- 0
    names(P_obs) <- COUNTS
    
    P_exp <- P_obs
    P_exp[] <- 0
    
    linkinvx <- poisson("log")$linkinv
    linkinvz <- binomial(object$linkz)$linkinv
    parms <- coef(object)
    kx <- ncol(object$X)
    kz <- ncol(object$Z)
    mu <- as.vector(linkinvx(object$X %*% parms[1:kx] + object$offsetx))
    phi <- as.vector(linkinvz(object$Z %*% parms[(kx + 1):(kx + kz)] + object$offsetz))
    #id0 <- object$Y == object$V
    Pmat <- matrix(0, nobs(object), length(COUNTS))
    colnames(Pmat) <- COUNTS
    
    PV <- if (object$truncate) {
        log(phi + (1 - phi) * dpois(object$V, 
            lambda = mu, log = FALSE) / (1-exp(-mu)))
    } else {
        log(phi + (1 - phi) * dpois(object$V, lambda = mu, log = FALSE))
    }
    for (i in COUNTS) {
        PC <- if (object$truncate) {
            log((1 - phi) * dpois(i, lambda = mu, log = FALSE) / (1-exp(-mu)))
        } else {
            log(1 - phi) + dpois(i, lambda = mu, log = TRUE)
        }
        Pmat[,as.character(i)] <- if (i == object$V)
            exp(PV) else exp(PC)
    }
    P_exp <- colMeans(Pmat)
    cbind(P_obs=P_obs, P_exp=P_exp)
}

## fit null model
mod0 <- vip(Y=y, X=X[,1,drop=FALSE], Z=Z[,1,drop=FALSE], V=2, truncate=TRUE)
## calculate GoF for null and other model
(gof0 <- goodness(mod0))
(gof <- goodness(mod))
## better model is closer to the 1:1 line
plot(gof0, type="b", col=2)
points(gof, type="b", col=4)
abline(0, 1, lty=2)
## better model will give smaller absolute deviation
sum(abs(apply(gof0, 1, diff)))
sum(abs(apply(gof, 1, diff)))
```
